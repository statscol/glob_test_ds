{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test-Transacion Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPMRs+M93ZySNKYVg8Z9OO7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/statscol/glob_test_ds/blob/main/Test_Transacion_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZuHDxL9J9j0"
      },
      "source": [
        "# 2. Purchases: Unusual Transactions approach\n",
        "### Description\n",
        "Using the data we'll train a model to find whether or not a transaction is unusual. This can be achieved by using one of the anomaly detection algorithms such as Isolation Forest based on the Random Forest Bagging Technique. However, data is not in a single file, so we have to download every single file using a selenium bot, merge it and transform it in order to train an Anomaly Detection Model. This is described in the following flowchart.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?id=1Ba_MLBSYsTLbAgecgRK5UsFSiHClvHx4',width=230 height=300>\n",
        "</center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6eWOGuIfuPo",
        "outputId": "9a4e3bfc-a717-4953-9825-4e8444c5feec"
      },
      "source": [
        "\n",
        "##pre configuration commands\n",
        "!pip install selenium\n",
        "!apt-get update \n",
        "!apt install chromium-chromedriver\n",
        "!mkdir transaction_data\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 24.1 MB/s eta 0:00:01\r\u001b[K     |▊                               | 20 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 51 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 81 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 92 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 102 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████                            | 112 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 122 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 133 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████                           | 143 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 153 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 163 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 174 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 184 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 194 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 204 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 215 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████                        | 225 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 235 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 245 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 256 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 266 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 276 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 286 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 296 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 307 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 317 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 327 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 337 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 348 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 358 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 368 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 378 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 389 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 399 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 409 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 419 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 430 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 440 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 450 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 460 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 471 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 481 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 491 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 501 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 512 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 522 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 532 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 542 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 552 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 563 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 573 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 583 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 593 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 604 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 614 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 624 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 634 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 645 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 655 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 665 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 675 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 686 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 696 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 706 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 716 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 727 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 737 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 747 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 757 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 768 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 778 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 788 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 798 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 808 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 819 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 829 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 839 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 849 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 860 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 870 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 880 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 890 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 901 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 904 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.7 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,258 kB]\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,420 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [505 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:18 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Ign:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [680 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,786 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [33.6 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [537 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,194 kB]\n",
            "Get:25 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [914 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,694 kB]\n",
            "Get:27 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [44.1 kB]\n",
            "Fetched 13.4 MB in 4s (3,575 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 93 not upgraded.\n",
            "Need to get 86.0 MB of archives.\n",
            "After this operation, 298 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 91.0.4472.101-0ubuntu0.18.04.1 [1,124 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 91.0.4472.101-0ubuntu0.18.04.1 [76.1 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 91.0.4472.101-0ubuntu0.18.04.1 [3,937 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 91.0.4472.101-0ubuntu0.18.04.1 [4,837 kB]\n",
            "Fetched 86.0 MB in 4s (23.0 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 160837 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_91.0.4472.101-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_91.0.4472.101-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_91.0.4472.101-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_91.0.4472.101-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN3z2LjlLBkN"
      },
      "source": [
        "from selenium import webdriver\n",
        "import time\n",
        "\n",
        "chrome_options_mod = webdriver.ChromeOptions()\n",
        "chrome_options_mod.add_argument('--headless')\n",
        "chrome_options_mod.add_argument('--no-sandbox')\n",
        "chrome_options_mod.add_argument('--disable-dev-shm-usage')\n",
        "prefs = {'download.default_directory' : '/content/transaction_data'}\n",
        "chrome_options_mod.add_experimental_option('prefs', prefs)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtPwPvBqLTEE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17bbf582-7b0d-405f-a228-4d775aa720ec"
      },
      "source": [
        "###get urls out of the index page site\n",
        "\n",
        "def get_data_urls(chrome_options):\n",
        "    \n",
        "    driver=webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "\n",
        "\n",
        "    driver.get('https://data.birmingham.gov.uk/dataset/purchase-card-transactions')\n",
        "    time.sleep(5) ##lets pretend we're not using a bot\n",
        "    data_ul=driver.find_element_by_class_name(\"resource-list\")\n",
        "    links=data_ul.find_elements_by_tag_name(\"a\")\n",
        "    filesData=[i.get_attribute('href') for i in links if 'xls' in i.get_attribute('href') ]\n",
        "    driver.close()\n",
        "    return(filesData)\n",
        "\n",
        "\n",
        "urls=get_data_urls(chrome_options_mod)\n",
        "urls[0:5] ##a sneak peek of the url's retrieved"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: use options instead of chrome_options\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://data.birmingham.gov.uk/dataset/cf552d08-cee9-43bf-8c0f-3196a9311799/resource/b4a15ade-11b1-4c98-88a0-8cd8408212ac/download/purchasecardtransactionsapril2014.xls',\n",
              " 'https://data.birmingham.gov.uk/dataset/cf552d08-cee9-43bf-8c0f-3196a9311799/resource/a8ebbfdc-6aa1-485c-b8ea-9f63f578ec33/download/purchasecardtransactionsmay2014.xls',\n",
              " 'https://data.birmingham.gov.uk/dataset/cf552d08-cee9-43bf-8c0f-3196a9311799/resource/70bb21b9-4d25-4a73-b641-faa42b02fda0/download/purchasecardtransactionsjune2014.xls',\n",
              " 'https://data.birmingham.gov.uk/dataset/cf552d08-cee9-43bf-8c0f-3196a9311799/resource/211b6316-7473-43b7-8461-70cfe4df076e/download/purchasecardtransactionsjuly2014.xls',\n",
              " 'https://data.birmingham.gov.uk/dataset/cf552d08-cee9-43bf-8c0f-3196a9311799/resource/f82e01b9-9bab-4ef5-b507-749cce10a7a8/download/purchasecardtransactionsaugust2014.xls']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm4FL8LvJPqB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "11a24b78-bc92-4e69-85e9-bbf981e20e87"
      },
      "source": [
        "def download_links(links,chrome_options):\n",
        " \n",
        "    driver =webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "    files_downloaded=0\n",
        "    for i in links:\n",
        "\n",
        "        print(\"[INFO] Downloading {}\".format(i.split(\"/\")[-1]))\n",
        "        driver.get(i)\n",
        "        files_downloaded+=1\n",
        "        print(\"[PROGRESS] {:.2%} of files downloaded \".format(files_downloaded/len(links)))\n",
        "        time.sleep(2)\n",
        "    driver.close()\n",
        "\n",
        "    return (\"[SUCCESS]\")\n",
        "\n",
        "    \n",
        "\n",
        "download_links(urls,chrome_options_mod)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: use options instead of chrome_options\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] Downloading purchasecardtransactionsapril2014.xls\n",
            "[PROGRESS] 2.27% of files downloaded \n",
            "[INFO] Downloading purchasecardtransactionsmay2014.xls\n",
            "[PROGRESS] 4.55% of files downloaded \n",
            "[INFO] Downloading purchasecardtransactionsjune2014.xls\n",
            "[PROGRESS] 6.82% of files downloaded \n",
            "[INFO] Downloading purchasecardtransactionsjuly2014.xls\n",
            "[PROGRESS] 9.09% of files downloaded \n",
            "[INFO] Downloading purchasecardtransactionsaugust2014.xls\n",
            "[PROGRESS] 11.36% of files downloaded \n",
            "[INFO] Downloading purchasecardtransactionsseptember2014.xls\n",
            "[PROGRESS] 13.64% of files downloaded \n",
            "[INFO] Downloading purchasecardtransactionsoctober2014.xls\n",
            "[PROGRESS] 15.91% of files downloaded \n",
            "[INFO] Downloading purchasecardsnov2014.xls\n",
            "[PROGRESS] 18.18% of files downloaded \n",
            "[INFO] Downloading purchasecardsdec2014.xls\n",
            "[PROGRESS] 20.45% of files downloaded \n",
            "[INFO] Downloading purchaseccardtransactionsjanuary2015.xls\n",
            "[PROGRESS] 22.73% of files downloaded \n",
            "[INFO] Downloading publishspendpurchasecardsfebruary.xls\n",
            "[PROGRESS] 25.00% of files downloaded \n",
            "[INFO] Downloading publishspendpurchasecardsmarch.xls\n",
            "[PROGRESS] 27.27% of files downloaded \n",
            "[INFO] Downloading svlrdclr05homesharechexefinainmngeneralappublishspendmay2015.xls\n",
            "[PROGRESS] 29.55% of files downloaded \n",
            "[INFO] Downloading publishspendjune2015alldirectorates.xls\n",
            "[PROGRESS] 31.82% of files downloaded \n",
            "[INFO] Downloading itemisedtransactionsjuly2015publishspend.xls\n",
            "[PROGRESS] 34.09% of files downloaded \n",
            "[INFO] Downloading itemisedtransactionsaugust2015publishspendalldirectorates.xls\n",
            "[PROGRESS] 36.36% of files downloaded \n",
            "[INFO] Downloading publishspendseptember2015.xls\n",
            "[PROGRESS] 38.64% of files downloaded \n",
            "[INFO] Downloading publishspendoctober2015.xls\n",
            "[PROGRESS] 40.91% of files downloaded \n",
            "[INFO] Downloading publishspendnovember2015.xls\n",
            "[PROGRESS] 43.18% of files downloaded \n",
            "[INFO] Downloading publishedspenddecember2015.xls\n",
            "[PROGRESS] 45.45% of files downloaded \n",
            "[INFO] Downloading publishspendjanuary2016.xls\n",
            "[PROGRESS] 47.73% of files downloaded \n",
            "[INFO] Downloading publishspendfebruary2016.xls\n",
            "[PROGRESS] 50.00% of files downloaded \n",
            "[INFO] Downloading publishspendmarch2016.xls\n",
            "[PROGRESS] 52.27% of files downloaded \n",
            "[INFO] Downloading publish-spend-april-2016.xls\n",
            "[PROGRESS] 54.55% of files downloaded \n",
            "[INFO] Downloading publish-spend-may-2016.xls\n",
            "[PROGRESS] 56.82% of files downloaded \n",
            "[INFO] Downloading publish-spend-june-2016.xls\n",
            "[PROGRESS] 59.09% of files downloaded \n",
            "[INFO] Downloading publish-spend-july-2016.xls\n",
            "[PROGRESS] 61.36% of files downloaded \n",
            "[INFO] Downloading publish-spend-august-2016.xls\n",
            "[PROGRESS] 63.64% of files downloaded \n",
            "[INFO] Downloading publish-spend-september-2016.xls\n",
            "[PROGRESS] 65.91% of files downloaded \n",
            "[INFO] Downloading publish-spend-october-2016.xls\n",
            "[PROGRESS] 68.18% of files downloaded \n",
            "[INFO] Downloading publishing-spend-november-2016.xls\n",
            "[PROGRESS] 70.45% of files downloaded \n",
            "[INFO] Downloading publish-spend-december-2016.xls\n",
            "[PROGRESS] 72.73% of files downloaded \n",
            "[INFO] Downloading cusersfinainmndesktoppublish-copy-january-2017.xls\n",
            "[PROGRESS] 75.00% of files downloaded \n",
            "[INFO] Downloading cusersfinainmndesktoppublish-spend-february-2017-all-directorates.xls\n",
            "[PROGRESS] 77.27% of files downloaded \n",
            "[INFO] Downloading cusersfinainmndesktoppublish-spend-march-2017.xls\n",
            "[PROGRESS] 79.55% of files downloaded \n",
            "[INFO] Downloading cusersfinainmndesktoppublish-spend-april-2017.xls\n",
            "[PROGRESS] 81.82% of files downloaded \n",
            "[INFO] Downloading cusersfinainmndesktoppublish-spend-may-2017.xls\n",
            "[PROGRESS] 84.09% of files downloaded \n",
            "[INFO] Downloading cusersfinainmndesktoppublish-spend-june--2017.xls\n",
            "[PROGRESS] 86.36% of files downloaded \n",
            "[INFO] Downloading cusersfinainmndesktoppublish-spend-july-2017.xls\n",
            "[PROGRESS] 88.64% of files downloaded \n",
            "[INFO] Downloading cusersfinainmndesktoppublish-spend-august-2017-all-directorates.xls\n",
            "[PROGRESS] 90.91% of files downloaded \n",
            "[INFO] Downloading cusersfinainmndesktoppublish-spend-sept-2017.xls\n",
            "[PROGRESS] 93.18% of files downloaded \n",
            "[INFO] Downloading cusersfinainmndesktoppublish-spend-october-2017-all-directorates.xls\n",
            "[PROGRESS] 95.45% of files downloaded \n",
            "[INFO] Downloading cusersfinainmndesktoppublish-spend-november-2017-all-directorates.xls\n",
            "[PROGRESS] 97.73% of files downloaded \n",
            "[INFO] Downloading cusersfinainmndesktoppublish-spend-january-2018.xls\n",
            "[PROGRESS] 100.00% of files downloaded \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[SUCCESS]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df8ZVvR2fcBg"
      },
      "source": [
        "### 2. Data Integration & Cleaning\n",
        "\n",
        "We have to modify column names before concatenating with the other files in order to prevent column duplicates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_td8yCdycppg",
        "outputId": "0d21d796-134d-4bae-ffc4-fb98713ac267"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "files=os.listdir(\"/content/transaction_data\")\n",
        "data_merged=pd.DataFrame(columns=['TRANS DATE', 'TRANS VAT DESC', 'ORIGINAL GROSS AMT', 'ORIGINAL CUR',\n",
        "       'BILLING GROSS AMT', 'BILLING CUR CODE', 'MERCHANT NAME', 'CARD NUMBER',\n",
        "       'TRANS CAC CODE 1', 'TRANS CAC DESC 1', 'TRANS CAC CODE 2',\n",
        "       'TRANS CAC DESC 2', 'TRANS CAC CODE 3', 'Directorate'])\n",
        "def adjust_column(col):\n",
        "  aux=col.strip()\n",
        "  return aux.replace(\"Directorates\",\"Directorate\")\n",
        "\n",
        "for f in files:\n",
        "  data1=pd.read_excel(\"/content/transaction_data/\"+f)\n",
        "  adj_cols=[adjust_column(i) for i in data1.columns.values]\n",
        "  data1.columns=adj_cols\n",
        "  if (\"Directorates\" in data1.columns.values):\n",
        "    print(f)\n",
        "  data_merged=pd.concat((data_merged,data1),axis=0)\n",
        "  print(\"[INFO] \"+f+\" Joined\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] cusersfinainmndesktoppublish-spend-april-2017.xls Joined\n",
            "[INFO] publishspendpurchasecardsmarch.xls Joined\n",
            "[INFO] purchasecardsdec2014.xls Joined\n",
            "[INFO] purchaseccardtransactionsjanuary2015.xls Joined\n",
            "[INFO] publish-spend-december-2016.xls Joined\n",
            "[INFO] cusersfinainmndesktoppublish-spend-january-2018.xls Joined\n",
            "[INFO] itemisedtransactionsaugust2015publishspendalldirectorates.xls Joined\n",
            "[INFO] purchasecardtransactionsjune2014.xls Joined\n",
            "[INFO] publish-spend-july-2016.xls Joined\n",
            "[INFO] cusersfinainmndesktoppublish-copy-january-2017.xls Joined\n",
            "[INFO] publish-spend-may-2016.xls Joined\n",
            "[INFO] cusersfinainmndesktoppublish-spend-august-2017-all-directorates.xls Joined\n",
            "[INFO] publishing-spend-november-2016.xls Joined\n",
            "[INFO] publish-spend-april-2016.xls Joined\n",
            "[INFO] purchasecardtransactionsapril2014.xls Joined\n",
            "[INFO] publishspendjune2015alldirectorates.xls Joined\n",
            "[INFO] cusersfinainmndesktoppublish-spend-june--2017.xls Joined\n",
            "[INFO] cusersfinainmndesktoppublish-spend-july-2017.xls Joined\n",
            "[INFO] svlrdclr05homesharechexefinainmngeneralappublishspendmay2015.xls Joined\n",
            "[INFO] cusersfinainmndesktoppublish-spend-may-2017.xls Joined\n",
            "[INFO] publish-spend-september-2016.xls Joined\n",
            "[INFO] cusersfinainmndesktoppublish-spend-march-2017.xls Joined\n",
            "[INFO] purchasecardtransactionsjuly2014.xls Joined\n",
            "[INFO] cusersfinainmndesktoppublish-spend-sept-2017.xls Joined\n",
            "[INFO] publishspendpurchasecardsfebruary.xls Joined\n",
            "[INFO] cusersfinainmndesktoppublish-spend-november-2017-all-directorates.xls Joined\n",
            "[INFO] publishspendmarch2016.xls Joined\n",
            "[INFO] publish-spend-august-2016.xls Joined\n",
            "[INFO] publishedspenddecember2015.xls Joined\n",
            "[INFO] publishspendoctober2015.xls Joined\n",
            "[INFO] publishspendseptember2015.xls Joined\n",
            "[INFO] publishspendjanuary2016.xls Joined\n",
            "[INFO] publishspendfebruary2016.xls Joined\n",
            "[INFO] publish-spend-june-2016.xls Joined\n",
            "[INFO] publish-spend-october-2016.xls Joined\n",
            "[INFO] cusersfinainmndesktoppublish-spend-october-2017-all-directorates.xls Joined\n",
            "[INFO] purchasecardtransactionsaugust2014.xls Joined\n",
            "[INFO] publishspendnovember2015.xls Joined\n",
            "[INFO] purchasecardtransactionsseptember2014.xls Joined\n",
            "[INFO] purchasecardsnov2014.xls Joined\n",
            "[INFO] cusersfinainmndesktoppublish-spend-february-2017-all-directorates.xls Joined\n",
            "[INFO] purchasecardtransactionsoctober2014.xls Joined\n",
            "[INFO] purchasecardtransactionsmay2014.xls Joined\n",
            "[INFO] itemisedtransactionsjuly2015publishspend.xls Joined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "Lb0GL7gokNHc",
        "outputId": "c00687d0-e3e3-4891-b50c-d37b7c0f756a"
      },
      "source": [
        "## lets look at the final data,seems like Billing Cur Code had a repeated column somewhere in the files considered. However, all the transactions were made in GB Pounds. So we'll skip this for now.\n",
        "data_merged.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TRANS DATE</th>\n",
              "      <th>TRANS VAT DESC</th>\n",
              "      <th>ORIGINAL GROSS AMT</th>\n",
              "      <th>ORIGINAL CUR</th>\n",
              "      <th>BILLING GROSS AMT</th>\n",
              "      <th>BILLING CUR CODE</th>\n",
              "      <th>MERCHANT NAME</th>\n",
              "      <th>CARD NUMBER</th>\n",
              "      <th>TRANS CAC CODE 1</th>\n",
              "      <th>TRANS CAC DESC 1</th>\n",
              "      <th>TRANS CAC CODE 2</th>\n",
              "      <th>TRANS CAC DESC 2</th>\n",
              "      <th>TRANS CAC CODE 3</th>\n",
              "      <th>Directorate</th>\n",
              "      <th>TRANS TAX AMT</th>\n",
              "      <th>BILLING CUR CODE.1</th>\n",
              "      <th>Unnamed: 10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-04-28</td>\n",
              "      <td>VR</td>\n",
              "      <td>66.38</td>\n",
              "      <td>GBP</td>\n",
              "      <td>66.38</td>\n",
              "      <td>GBP</td>\n",
              "      <td>millpool service s</td>\n",
              "      <td>************5770</td>\n",
              "      <td>K020</td>\n",
              "      <td>Vehicle Fuel</td>\n",
              "      <td>RV12N</td>\n",
              "      <td>African-Caribbean DC</td>\n",
              "      <td>A00</td>\n",
              "      <td>Adult &amp; Communities</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-04-28</td>\n",
              "      <td>VR</td>\n",
              "      <td>25.25</td>\n",
              "      <td>GBP</td>\n",
              "      <td>25.25</td>\n",
              "      <td>GBP</td>\n",
              "      <td>shell fiveways 387</td>\n",
              "      <td>************1147</td>\n",
              "      <td>K020</td>\n",
              "      <td>Vehicle Fuel</td>\n",
              "      <td>RV1K2</td>\n",
              "      <td>Elders Group - Ladywood</td>\n",
              "      <td>A00</td>\n",
              "      <td>Adult &amp; Communities</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-04-26</td>\n",
              "      <td>VR</td>\n",
              "      <td>81.75</td>\n",
              "      <td>GBP</td>\n",
              "      <td>81.75</td>\n",
              "      <td>GBP</td>\n",
              "      <td>shell fiveways 387</td>\n",
              "      <td>************1147</td>\n",
              "      <td>K020</td>\n",
              "      <td>Vehicle Fuel</td>\n",
              "      <td>RV1K2</td>\n",
              "      <td>Elders Group - Ladywood</td>\n",
              "      <td>A00</td>\n",
              "      <td>Adult &amp; Communities</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-04-07</td>\n",
              "      <td>VR</td>\n",
              "      <td>73.29</td>\n",
              "      <td>GBP</td>\n",
              "      <td>73.29</td>\n",
              "      <td>GBP</td>\n",
              "      <td>shell fiveways 387</td>\n",
              "      <td>************1147</td>\n",
              "      <td>K020</td>\n",
              "      <td>Vehicle Fuel</td>\n",
              "      <td>RV1K2</td>\n",
              "      <td>Elders Group - Ladywood</td>\n",
              "      <td>A00</td>\n",
              "      <td>Adult &amp; Communities</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-04-05</td>\n",
              "      <td>VR</td>\n",
              "      <td>75.70</td>\n",
              "      <td>GBP</td>\n",
              "      <td>75.70</td>\n",
              "      <td>GBP</td>\n",
              "      <td>shell fiveways 387</td>\n",
              "      <td>************1147</td>\n",
              "      <td>K020</td>\n",
              "      <td>Vehicle Fuel</td>\n",
              "      <td>RV1K2</td>\n",
              "      <td>Elders Group - Ladywood</td>\n",
              "      <td>A00</td>\n",
              "      <td>Adult &amp; Communities</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  TRANS DATE TRANS VAT DESC  ...  BILLING CUR CODE.1 Unnamed: 10\n",
              "0 2017-04-28             VR  ...                 NaN         NaN\n",
              "1 2017-04-28             VR  ...                 NaN         NaN\n",
              "2 2017-04-26             VR  ...                 NaN         NaN\n",
              "3 2017-04-07             VR  ...                 NaN         NaN\n",
              "4 2017-04-05             VR  ...                 NaN         NaN\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KenIaTqHfJ8P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b530120f-03a4-467c-9779-7e2ab4e5333a"
      },
      "source": [
        "### Transaction Date itself doesnt add much for Anomaly Detection, but the day of the week surely does. Lets get it out of the transaction date using Pandas dt\n",
        "### We also select a few columns to train the model. Only controllable features were selected (Trans CAC CODE 2 and 3 had a huge number of labels so for the sake of this test, will not be considered)\n",
        "\n",
        "data_merged['dayWeek']=data_merged[\"TRANS DATE\"].dt.dayofweek\n",
        "data_mod=data_merged[['ORIGINAL GROSS AMT','dayWeek','TRANS CAC CODE 1','Directorate']]\n",
        "data_mod.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ORIGINAL GROSS AMT</th>\n",
              "      <th>dayWeek</th>\n",
              "      <th>TRANS CAC CODE 1</th>\n",
              "      <th>Directorate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>66.38</td>\n",
              "      <td>4.0</td>\n",
              "      <td>K020</td>\n",
              "      <td>Adult &amp; Communities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25.25</td>\n",
              "      <td>4.0</td>\n",
              "      <td>K020</td>\n",
              "      <td>Adult &amp; Communities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>81.75</td>\n",
              "      <td>2.0</td>\n",
              "      <td>K020</td>\n",
              "      <td>Adult &amp; Communities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>73.29</td>\n",
              "      <td>4.0</td>\n",
              "      <td>K020</td>\n",
              "      <td>Adult &amp; Communities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>75.70</td>\n",
              "      <td>2.0</td>\n",
              "      <td>K020</td>\n",
              "      <td>Adult &amp; Communities</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ORIGINAL GROSS AMT  dayWeek TRANS CAC CODE 1          Directorate\n",
              "0               66.38      4.0             K020  Adult & Communities\n",
              "1               25.25      4.0             K020  Adult & Communities\n",
              "2               81.75      2.0             K020  Adult & Communities\n",
              "3               73.29      4.0             K020  Adult & Communities\n",
              "4               75.70      2.0             K020  Adult & Communities"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqk7KD9fhUgw"
      },
      "source": [
        "### 3. Model Training\n",
        "Given the data conditions, factors with multiple categories (more than 100), we'll need to use a dimensionality reduction technique, such as PCA. This will feed the Anomaly/Outlier detection algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALiND7yZhTCN"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder,LabelBinarizer,StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline,make_pipeline\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn_pandas import DataFrameMapper\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import IsolationForest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQBqXdBsdj-X"
      },
      "source": [
        "##there are some missing values, lets use the median or the mode, this will prevent from changing the true distribution of data\n",
        "data_mod_imp=data_mod[['TRANS CAC CODE 1','Directorate']].apply(lambda x: x.fillna(x.value_counts().index[0]))\n",
        "data_mod_imp['ORIGINAL GROSS AMT']=data_mod['ORIGINAL GROSS AMT']\n",
        "data_mod_imp['dayWeek']=data_mod['dayWeek']\n",
        "data_mod_imp.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfkNcQwRmeH3"
      },
      "source": [
        "##variables to build as one-hot-encoding\n",
        "to_one_hot=['TRANS CAC CODE 1','Directorate']\n",
        "mapper_one_hot = DataFrameMapper(\n",
        "    [(d, LabelBinarizer()) for d in to_one_hot]\n",
        ")\n",
        "\n",
        "\n",
        "##Define all the steps, from one_hot encoding to model training in a pipeline\n",
        "\n",
        "pipeline_forest = Pipeline(steps=[\n",
        "\t(\"mapper\", mapper_one_hot),\n",
        "\t(\"pca\", PCA(n_components = 10)),\n",
        "\t(\"svm\", IsolationForest(contamination=0.01))])\n",
        "\n",
        "\n",
        "pipeline_forest.fit(X=data_mod_imp)\n",
        "trans_type=pipeline_forest.predict(data_mod_imp)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS_KY3KakXqH",
        "outputId": "e71e3ed3-eee0-4745-9edb-97518c847c2e"
      },
      "source": [
        "##lets see which transactions are classified as outliers/anom\n",
        "data_mod_imp['type_transaction']=trans_type\n",
        "print(\"[INFO] iForest found that {:.2%} of the transactions were uncommon, possible value at risk: {:.2f} £\".format(sum(trans_type==-1)/len(trans_type),sum((trans_type==-1)*data_mod_imp['ORIGINAL GROSS AMT'].values)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] iForest found that 0.90% of the transactions were uncommon, possible value at risk: 337963.24 £\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7IYVUIVnl4T"
      },
      "source": [
        "### Final Comments and Further Work\n",
        "\n",
        "We've trained an algorithm based on Random Forest which is able to determine  whether or not a transaction is an anomaly/outlier. This approach could be improved by using more data and other algorithms. However a testing set is compulsory for this kind of analysis. By using it we could assess the quality of the anomaly detection model."
      ]
    }
  ]
}